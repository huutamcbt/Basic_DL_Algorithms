{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[]\n",
      "Tensorflow version: 2.10.0\n",
      "Keras version: 2.10.0\n",
      "Running on GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.config.list_physical_devices('APU'))\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "print(\"Keras version:\", tf.keras.__version__)\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Running on GPU\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataScaling:\n",
    "    def simple_features_scaling(self, pData):\n",
    "        max = np.max(pData)\n",
    "        \n",
    "        return pData / max \n",
    "    \n",
    "    def min_max_scaling(self, pData):\n",
    "        min = np.min(pData)\n",
    "        max = np.max(pData)\n",
    "\n",
    "        return (pData - min) / (max - min)\n",
    "    \n",
    "\n",
    "class Normalization:\n",
    "    def standardization(self, pData):\n",
    "        std = np.std(pData)\n",
    "        mean = np.mean(pData)\n",
    "\n",
    "        return (pData - mean) / std\n",
    "    \n",
    "    def mean_normal(self, pData):\n",
    "        mean = np.mean(pData)\n",
    "        max = np.max(pData)\n",
    "        min = np.min(pData)\n",
    "\n",
    "        return (pData - mean) / (max - min)\n",
    "\n",
    "    def box_cox_normal(self, pData):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\"\"\"\n",
    "    All vector on this class is transfer to column vector before put it into function\n",
    "    This model use stochastic gradient descent\n",
    "\"\"\"\n",
    "# This is implementation of Linear Regression for Gradient Descent\n",
    "class LinearRegression:\n",
    "    def __init__(self, n_features):\n",
    "        # This variable stores all weights and biases\n",
    "        self.weights = None\n",
    "\n",
    "        # N features in dataset\n",
    "        self.n_features = n_features\n",
    "\n",
    "        # This variable saves all cost values which get by each loop \n",
    "        self.costs = []\n",
    "\n",
    "        # Save loss for each loop\n",
    "        self.losses = []\n",
    "    \n",
    "    def initialize_param(self):\n",
    "        # Init the random value for weights and bias\n",
    "        self.weights = np.random.randn(self.n_features + 1, 1)\n",
    "\n",
    "    # Compute derivative value using gradient descent\n",
    "    def gradient(self, py_hat, py, pX):\n",
    "        return 2*(py_hat - py)*pX.reshape(-1,1)\n",
    "    \n",
    "    # Update the weights using formular with parameters are learning rate, derivative of Loss function\n",
    "    def update_weights(self, pLr, pGradient):\n",
    "        self.weights = self.weights - pLr*pGradient\n",
    "    \n",
    "    # This function processes training the model using dataset\n",
    "    def fit(self, pX_train, py_train, learning_rate = 0.01, epoch = 100):\n",
    "        # Each vector in pX_train is row vector\n",
    "        # N is lenght of rows of pX_train\n",
    "        N = pX_train.shape[0]\n",
    "        self.initialize_param()\n",
    "        for e in range(epoch):\n",
    "            costs = 0\n",
    "            for i in range(N):\n",
    "                # Extract x, y data from dataset for each loop\n",
    "                x = pX_train[i]\n",
    "                y = py_train[i]\n",
    "            \n",
    "                y_hat = self.predict(x)\n",
    "            \n",
    "                # compute loss\n",
    "                costs += self.compute_loss(y, y_hat)\n",
    "\n",
    "                theta = self.gradient(y_hat, y, x)\n",
    "                \n",
    "                # Update weights\n",
    "                self.update_weights(learning_rate, theta)\n",
    "            \n",
    "            # Append mean cost for each loop\n",
    "            self.costs.append(np.sqrt(1.0 / N * costs))\n",
    "    # Predict the y value using model\n",
    "    def predict(self, pX):\n",
    "        # The pX is row vector\n",
    "        return np.dot(pX, self.weights)\n",
    "    \n",
    "    # Plot the cost through each loop\n",
    "    def plot_cost(self, pStart, pEnd):\n",
    "        plt.figure()\n",
    "        plt.plot(self.costs)\n",
    "        plt.xlim(pStart, pEnd)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "    \n",
    "    def get_losses(self):\n",
    "        return self.losses\n",
    "    \n",
    "    def get_costs(self):\n",
    "        return self.costs\n",
    "    \n",
    "    # Compute loss value once predict new value\n",
    "    def compute_loss(self, py, py_hat):\n",
    "        return 1.0 / 2 * (py - py_hat)**2\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def evaluate_model(self, pX_test, py_test):\n",
    "        N = pX_test.shape[0]\n",
    "\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        for i in range(N):\n",
    "            y_hat = self.predict(pX_test[i])\n",
    "            loss += self.compute_loss(py_test[i], y_hat)\n",
    "            print(self.compute_loss(py_test[i], y_hat))\n",
    "\n",
    "        loss = np.sqrt(1.0 / N * loss)\n",
    "        accuracy = 1 - loss\n",
    "       \n",
    "def pre_processing(pX):\n",
    "    # Normalize the data with suitable value\n",
    "    normalizer = Normalization()\n",
    "    pX = normalizer.mean_normal(pX)\n",
    "\n",
    "    # Add one vector into X matrix\n",
    "    pX = np.concatenate((np.ones((pX.shape[0],1)), pX), axis=1)\n",
    "\n",
    "    return pX\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('data/advertising.csv')\n",
    "    dataset = df.to_numpy()\n",
    "    lr = 0.01\n",
    "    epoches = 5000\n",
    "    mini_batch = 90\n",
    "    \n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:, -1].reshape(-1,1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    linear = LinearRegression(X_train.shape[1])\n",
    "    \n",
    "    # Pre-processing X data\n",
    "    X_train = pre_processing(X_train)\n",
    "    X_test = pre_processing(X_test)\n",
    "\n",
    "    linear.fit(X_train, y_train, learning_rate=lr, epoch=epoches)\n",
    "    linear.plot_cost(0, epoches)\n",
    "    linear.evaluate_model(pX_test=X_test, py_test=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    All vector on this class is transfer to column vector before put it into function\n",
    "    This model use mini-batch gradient descent\n",
    "\"\"\"\n",
    "# This is implementation of Linear Regression for Gradient Descent\n",
    "class LinearRegression:\n",
    "    def __init__(self, n_features):\n",
    "        # This variable stores all weights and biases\n",
    "        self.weights = None\n",
    "\n",
    "        # N features in dataset\n",
    "        self.n_features = n_features\n",
    "\n",
    "        # This variable saves all cost values which get by each loop \n",
    "        self.costs = []\n",
    "\n",
    "        # Save loss for each loop\n",
    "        self.losses = []\n",
    "    \n",
    "    def initialize_param(self):\n",
    "        # Init the random value for weights and bias\n",
    "        self.weights = np.random.randn(self.n_features + 1, 1)\n",
    "\n",
    "    # Compute derivative value using gradient descent\n",
    "    def gradient(self, py_hat, py, pX):\n",
    "        return (2*(py_hat - py)*pX).reshape(self.n_features + 1, -1).mean(axis = 1, dtype= np.float32)\n",
    "    \n",
    "    # Update the weights using formular with parameters are learning rate, derivative of Loss function\n",
    "    def update_weights(self, pLr, pGradient):\n",
    "        self.weights = self.weights - pLr*pGradient\n",
    "    \n",
    "    # This function processes training the model using dataset\n",
    "    def fit(self, pX_train, py_train, learning_rate = 0.01, epoch = 100, mini_batch = 90):\n",
    "        # Each vector in pX_train is row vector\n",
    "        # N is lenght of rows of pX_train\n",
    "        N = pX_train.shape[0]\n",
    "        self.initialize_param()\n",
    "        temp_dataset = np.concatenate((pX_train, py_train), axis= 1)\n",
    "        for e in range(epoch):\n",
    "            costs = 0\n",
    "            # Shuffle all dataset for the next training\n",
    "            np.random.shuffle(temp_dataset)\n",
    "            X_train = temp_dataset[:, :-1]\n",
    "            y_train = temp_dataset[:, -1].reshape(-1,1)\n",
    "            for i in range(0, N, mini_batch):\n",
    "                # Extract x, y data from dataset for each loop\n",
    "                x = X_train[i: i + mini_batch]\n",
    "                y = y_train[i: i + mini_batch]\n",
    "\n",
    "                y_hat = self.predict(x)\n",
    "                \n",
    "                # compute loss\n",
    "                costs += self.compute_loss(y, y_hat)\n",
    "\n",
    "                theta = self.gradient(y_hat, y, x)\n",
    "                theta = theta.reshape(self.n_features + 1, -1)\n",
    "                # Update weights\n",
    "                self.update_weights(learning_rate, theta)\n",
    "            \n",
    "            # Append mean cost for each loop\n",
    "            self.costs.append(np.sqrt(mini_batch / N * costs))\n",
    "    # Predict the y value using model\n",
    "    def predict(self, pX):\n",
    "        # The pX is row vector\n",
    "        \n",
    "        return np.dot(pX, self.weights)\n",
    "    \n",
    "    # Plot the cost through each loop\n",
    "    def plot_cost(self, pStart, pEnd):\n",
    "        plt.figure()\n",
    "        plt.plot(self.costs)\n",
    "        plt.xlim(pStart, pEnd)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "    \n",
    "    def get_losses(self):\n",
    "        return self.losses\n",
    "    \n",
    "    def get_costs(self):\n",
    "        return self.costs\n",
    "    \n",
    "    # Compute loss value once predict new value\n",
    "    def compute_loss(self, py, py_hat):\n",
    "        loss = np.mean(1.0 / 2 * (py - py_hat)**2, axis=0, dtype=np.float32)\n",
    "        # print(loss)\n",
    "        return loss\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def evaluate_model(self, pX_test, py_test):\n",
    "        N = pX_test.shape[0]\n",
    "\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        for i in range(N):\n",
    "            y_hat = self.predict(pX_test[i])\n",
    "            loss += self.compute_loss(py_test[i], y_hat)\n",
    "            print(self.compute_loss(py_test[i], y_hat))\n",
    "\n",
    "        loss = np.sqrt(1.0 / N * loss)\n",
    "        accuracy = 1 - loss\n",
    "       \n",
    "def pre_processing(pX, is_normalized=True):\n",
    "    # Normalize the data with suitable value\n",
    "    normalizer = Normalization()\n",
    "    if is_normalized == True:\n",
    "        pX = normalizer.mean_normal(pX)\n",
    "    \n",
    "    # Add one vector into X matrix\n",
    "    pX = np.concatenate((np.ones((pX.shape[0],1)), pX), axis=1)\n",
    "\n",
    "    return pX\n",
    "\n",
    "df = pd.read_csv('data/advertising.csv')\n",
    "dataset = df.to_numpy()\n",
    "lr = 0.01\n",
    "epoches = 50000\n",
    "mini_batch = 70\n",
    "is_splited = True\n",
    "X_train = X_test = y_train = y_test = None\n",
    "X = dataset[:, :-1]\n",
    "y = dataset[:, -1].reshape(-1,1)\n",
    "\n",
    "if is_splited == True:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    X_train, y_train = X, y\n",
    "    X_test = y_test = [] \n",
    "\n",
    "linear = LinearRegression(X_train.shape[1])\n",
    "\n",
    "# Pre-processing X data\n",
    "X_train = pre_processing(X_train, is_normalized=True)\n",
    "# X_test = pre_processing(X_test)\n",
    "linear.fit(X_train, y_train, learning_rate=lr, epoch=epoches, mini_batch=mini_batch)\n",
    "linear.plot_cost(0, epoches)\n",
    "# linear.evaluate_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74980143]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/or_problem.csv')\n",
    "dataset = df.to_numpy()\n",
    "\n",
    "X = dataset[:, :-1]\n",
    "y = dataset[:, -1].reshape(-1,1)\n",
    "\n",
    "\n",
    "linear.predict(pre_processing(np.array([0,1]).reshape(1,2), is_normalized=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
